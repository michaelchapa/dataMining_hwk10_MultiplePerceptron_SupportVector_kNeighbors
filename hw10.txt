A)
For e2 of C',
object p is selected and the e2-neighborhood of p is checked if it contains at least MinPts objects. 
Since e1 of C has a smaller radius than e2 and is presumabely using the same object p, the objects in its smaller radius will be a subset of the e2 larger radius.

B)
CLIQUE -> finds dense cells in all sub-spaces.

Identify subspaces that contain clusters:
	Partition the data space into the grid-structure and find the number of points that lie inside each cell of the partition
	Identify the subspaces that contain clusters using the Apriori principle
Identify clusters:
	Determine dense units in all subspaces of interest.
	Determine connected dense units in all subspaces of interest. 
Generate minimal descriptions for the clusters:
	Determine maximal regions that cover a cluster of connected dense units for each cluster. 
	Determine minimal cover for each cluster. 

C)
See code in hwk10.py for implementation.

OUTPUT:
Split Training: X: (480, 7) y: (480,)
Split Testing: X: (20, 7) y: (20,) 


Multi-layer Perceptron Classifier, hidden layer size: 100, activation fxn: RELU
Accuracy: 0.90, Loss: 0.02

Multi-layer Perceptron Classifier, hidden layer size: 200, activation fxn: Logistic
Accuracy: 0.95, Loss: 0.25


C-Support Vector Classifier, C: .1, kernel: rbf
Accuracy: 0.85

C-Support Vector Classifier, C: .001, kernel: poly
Accuracy: 0.55

C-Support Vector Classifier, C: 1, kernel: sigmoid
Accuracy: 0.90


K-nearest neighbors Classifier, n_neighbors: 2
Accuracy: 0.75

K-nearest neighbors Classifier, n_neighbors: 3
Accuracy: 0.65

K-nearest neighbors Classifier, n_neighbors: 4
Accuracy: 0.85